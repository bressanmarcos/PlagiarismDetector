{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detector\n",
    "In this notebook, I examine text files to perform data classification. Each file is labeled as either plagiarized or not.\n",
    "The notebook was created to be used in **AWS Sagemaker** environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and save locally\n",
    "\n",
    "Source for database: \n",
    "\n",
    "Clough, P. and Stevenson, M. Developing A Corpus of Plagiarised Short Answers, Language Resources and Evaluation: Special Issue on Plagiarism and Authorship Analysis, In Press. [Download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-03-23 13:58:44--  https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.184.189\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.184.189|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 113826 (111K) [application/zip]\n",
      "Saving to: ‘data.zip.1’\n",
      "\n",
      "data.zip.1          100%[===================>] 111.16K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2021-03-23 13:58:45 (3.23 MB/s) - ‘data.zip.1’ saved [113826/113826]\n",
      "\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/.DS_Store          \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/data/\n",
      "  inflating: __MACOSX/data/._.DS_Store  \n",
      "  inflating: data/file_information.csv  \n",
      "  inflating: __MACOSX/data/._file_information.csv  \n",
      "  inflating: data/g0pA_taska.txt     \n",
      "  inflating: __MACOSX/data/._g0pA_taska.txt  \n",
      "  inflating: data/g0pA_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g0pA_taskb.txt  \n",
      "  inflating: data/g0pA_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g0pA_taskc.txt  \n",
      "  inflating: data/g0pA_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g0pA_taskd.txt  \n",
      "  inflating: data/g0pA_taske.txt     \n",
      "  inflating: __MACOSX/data/._g0pA_taske.txt  \n",
      "  inflating: data/g0pB_taska.txt     \n",
      "  inflating: __MACOSX/data/._g0pB_taska.txt  \n",
      "  inflating: data/g0pB_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g0pB_taskb.txt  \n",
      "  inflating: data/g0pB_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g0pB_taskc.txt  \n",
      "  inflating: data/g0pB_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g0pB_taskd.txt  \n",
      "  inflating: data/g0pB_taske.txt     \n",
      "  inflating: __MACOSX/data/._g0pB_taske.txt  \n",
      "  inflating: data/g0pC_taska.txt     \n",
      "  inflating: __MACOSX/data/._g0pC_taska.txt  \n",
      "  inflating: data/g0pC_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g0pC_taskb.txt  \n",
      "  inflating: data/g0pC_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g0pC_taskc.txt  \n",
      "  inflating: data/g0pC_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g0pC_taskd.txt  \n",
      "  inflating: data/g0pC_taske.txt     \n",
      "  inflating: __MACOSX/data/._g0pC_taske.txt  \n",
      "  inflating: data/g0pD_taska.txt     \n",
      "  inflating: __MACOSX/data/._g0pD_taska.txt  \n",
      "  inflating: data/g0pD_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g0pD_taskb.txt  \n",
      "  inflating: data/g0pD_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g0pD_taskc.txt  \n",
      "  inflating: data/g0pD_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g0pD_taskd.txt  \n",
      "  inflating: data/g0pD_taske.txt     \n",
      "  inflating: __MACOSX/data/._g0pD_taske.txt  \n",
      "  inflating: data/g0pE_taska.txt     \n",
      "  inflating: __MACOSX/data/._g0pE_taska.txt  \n",
      "  inflating: data/g0pE_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g0pE_taskb.txt  \n",
      "  inflating: data/g0pE_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g0pE_taskc.txt  \n",
      "  inflating: data/g0pE_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g0pE_taskd.txt  \n",
      "  inflating: data/g0pE_taske.txt     \n",
      "  inflating: __MACOSX/data/._g0pE_taske.txt  \n",
      "  inflating: data/g1pA_taska.txt     \n",
      "  inflating: __MACOSX/data/._g1pA_taska.txt  \n",
      "  inflating: data/g1pA_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g1pA_taskb.txt  \n",
      "  inflating: data/g1pA_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g1pA_taskc.txt  \n",
      "  inflating: data/g1pA_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g1pA_taskd.txt  \n",
      "  inflating: data/g1pA_taske.txt     \n",
      "  inflating: __MACOSX/data/._g1pA_taske.txt  \n",
      "  inflating: data/g1pB_taska.txt     \n",
      "  inflating: __MACOSX/data/._g1pB_taska.txt  \n",
      "  inflating: data/g1pB_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g1pB_taskb.txt  \n",
      "  inflating: data/g1pB_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g1pB_taskc.txt  \n",
      "  inflating: data/g1pB_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g1pB_taskd.txt  \n",
      "  inflating: data/g1pB_taske.txt     \n",
      "  inflating: __MACOSX/data/._g1pB_taske.txt  \n",
      "  inflating: data/g1pD_taska.txt     \n",
      "  inflating: __MACOSX/data/._g1pD_taska.txt  \n",
      "  inflating: data/g1pD_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g1pD_taskb.txt  \n",
      "  inflating: data/g1pD_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g1pD_taskc.txt  \n",
      "  inflating: data/g1pD_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g1pD_taskd.txt  \n",
      "  inflating: data/g1pD_taske.txt     \n",
      "  inflating: __MACOSX/data/._g1pD_taske.txt  \n",
      "  inflating: data/g2pA_taska.txt     \n",
      "  inflating: __MACOSX/data/._g2pA_taska.txt  \n",
      "  inflating: data/g2pA_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g2pA_taskb.txt  \n",
      "  inflating: data/g2pA_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g2pA_taskc.txt  \n",
      "  inflating: data/g2pA_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g2pA_taskd.txt  \n",
      "  inflating: data/g2pA_taske.txt     \n",
      "  inflating: __MACOSX/data/._g2pA_taske.txt  \n",
      "  inflating: data/g2pB_taska.txt     \n",
      "  inflating: __MACOSX/data/._g2pB_taska.txt  \n",
      "  inflating: data/g2pB_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g2pB_taskb.txt  \n",
      "  inflating: data/g2pB_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g2pB_taskc.txt  \n",
      "  inflating: data/g2pB_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g2pB_taskd.txt  \n",
      "  inflating: data/g2pB_taske.txt     \n",
      "  inflating: __MACOSX/data/._g2pB_taske.txt  \n",
      "  inflating: data/g2pC_taska.txt     \n",
      "  inflating: __MACOSX/data/._g2pC_taska.txt  \n",
      "  inflating: data/g2pC_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g2pC_taskb.txt  \n",
      "  inflating: data/g2pC_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g2pC_taskc.txt  \n",
      "  inflating: data/g2pC_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g2pC_taskd.txt  \n",
      "  inflating: data/g2pC_taske.txt     \n",
      "  inflating: __MACOSX/data/._g2pC_taske.txt  \n",
      "  inflating: data/g2pE_taska.txt     \n",
      "  inflating: __MACOSX/data/._g2pE_taska.txt  \n",
      "  inflating: data/g2pE_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g2pE_taskb.txt  \n",
      "  inflating: data/g2pE_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g2pE_taskc.txt  \n",
      "  inflating: data/g2pE_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g2pE_taskd.txt  \n",
      "  inflating: data/g2pE_taske.txt     \n",
      "  inflating: __MACOSX/data/._g2pE_taske.txt  \n",
      "  inflating: data/g3pA_taska.txt     \n",
      "  inflating: __MACOSX/data/._g3pA_taska.txt  \n",
      "  inflating: data/g3pA_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g3pA_taskb.txt  \n",
      "  inflating: data/g3pA_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g3pA_taskc.txt  \n",
      "  inflating: data/g3pA_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g3pA_taskd.txt  \n",
      "  inflating: data/g3pA_taske.txt     \n",
      "  inflating: __MACOSX/data/._g3pA_taske.txt  \n",
      "  inflating: data/g3pB_taska.txt     \n",
      "  inflating: __MACOSX/data/._g3pB_taska.txt  \n",
      "  inflating: data/g3pB_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g3pB_taskb.txt  \n",
      "  inflating: data/g3pB_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g3pB_taskc.txt  \n",
      "  inflating: data/g3pB_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g3pB_taskd.txt  \n",
      "  inflating: data/g3pB_taske.txt     \n",
      "  inflating: __MACOSX/data/._g3pB_taske.txt  \n",
      "  inflating: data/g3pC_taska.txt     \n",
      "  inflating: __MACOSX/data/._g3pC_taska.txt  \n",
      "  inflating: data/g3pC_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g3pC_taskb.txt  \n",
      "  inflating: data/g3pC_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g3pC_taskc.txt  \n",
      "  inflating: data/g3pC_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g3pC_taskd.txt  \n",
      "  inflating: data/g3pC_taske.txt     \n",
      "  inflating: __MACOSX/data/._g3pC_taske.txt  \n",
      "  inflating: data/g4pB_taska.txt     \n",
      "  inflating: __MACOSX/data/._g4pB_taska.txt  \n",
      "  inflating: data/g4pB_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g4pB_taskb.txt  \n",
      "  inflating: data/g4pB_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g4pB_taskc.txt  \n",
      "  inflating: data/g4pB_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g4pB_taskd.txt  \n",
      "  inflating: data/g4pB_taske.txt     \n",
      "  inflating: __MACOSX/data/._g4pB_taske.txt  \n",
      "  inflating: data/g4pC_taska.txt     \n",
      "  inflating: __MACOSX/data/._g4pC_taska.txt  \n",
      "  inflating: data/g4pC_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g4pC_taskb.txt  \n",
      "  inflating: data/g4pC_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g4pC_taskc.txt  \n",
      "  inflating: data/g4pC_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g4pC_taskd.txt  \n",
      "  inflating: data/g4pC_taske.txt     \n",
      "  inflating: __MACOSX/data/._g4pC_taske.txt  \n",
      "  inflating: data/g4pD_taska.txt     \n",
      "  inflating: __MACOSX/data/._g4pD_taska.txt  \n",
      "  inflating: data/g4pD_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g4pD_taskb.txt  \n",
      "  inflating: data/g4pD_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g4pD_taskc.txt  \n",
      "  inflating: data/g4pD_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g4pD_taskd.txt  \n",
      "  inflating: data/g4pD_taske.txt     \n",
      "  inflating: __MACOSX/data/._g4pD_taske.txt  \n",
      "  inflating: data/g4pE_taska.txt     \n",
      "  inflating: __MACOSX/data/._g4pE_taska.txt  \n",
      "  inflating: data/g4pE_taskb.txt     \n",
      "  inflating: __MACOSX/data/._g4pE_taskb.txt  \n",
      "  inflating: data/g4pE_taskc.txt     \n",
      "  inflating: __MACOSX/data/._g4pE_taskc.txt  \n",
      "  inflating: data/g4pE_taskd.txt     \n",
      "  inflating: __MACOSX/data/._g4pE_taskd.txt  \n",
      "  inflating: data/g4pE_taske.txt     \n",
      "  inflating: __MACOSX/data/._g4pE_taske.txt  \n",
      "  inflating: data/orig_taska.txt     \n",
      "  inflating: __MACOSX/data/._orig_taska.txt  \n",
      "  inflating: data/orig_taskb.txt     \n",
      "  inflating: data/orig_taskc.txt     \n",
      "  inflating: __MACOSX/data/._orig_taskc.txt  \n",
      "  inflating: data/orig_taskd.txt     \n",
      "  inflating: __MACOSX/data/._orig_taskd.txt  \n",
      "  inflating: data/orig_taske.txt     \n",
      "  inflating: __MACOSX/data/._orig_taske.txt  \n",
      "  inflating: data/test_info.csv      \n",
      "  inflating: __MACOSX/data/._test_info.csv  \n",
      "  inflating: __MACOSX/._data         \n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
    "!unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plagiarism dataset is made of multiple text files; each of these files has characteristics that are is summarized in a .csv file named file_information.csv, which we can read in using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non\n",
       "5  g0pB_taska.txt    a      non\n",
       "6  g0pB_taskb.txt    b      non\n",
       "7  g0pB_taskc.txt    c      cut\n",
       "8  g0pB_taskd.txt    d    light\n",
       "9  g0pB_taske.txt    e    heavy"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Task</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>g0pA_taska.txt</td>\n      <td>a</td>\n      <td>non</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>g0pA_taskb.txt</td>\n      <td>b</td>\n      <td>cut</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g0pA_taskc.txt</td>\n      <td>c</td>\n      <td>light</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g0pA_taskd.txt</td>\n      <td>d</td>\n      <td>heavy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g0pA_taske.txt</td>\n      <td>e</td>\n      <td>non</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>g0pB_taska.txt</td>\n      <td>a</td>\n      <td>non</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>g0pB_taskb.txt</td>\n      <td>b</td>\n      <td>non</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>g0pB_taskc.txt</td>\n      <td>c</td>\n      <td>cut</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>g0pB_taskd.txt</td>\n      <td>d</td>\n      <td>light</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>g0pB_taske.txt</td>\n      <td>e</td>\n      <td>heavy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "plagiarism_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Text extracted from original source)\n",
    "### Five task types, A-E\n",
    "Each text file contains an answer to one short question; these questions are labeled as tasks A-E.\n",
    "\n",
    "- Each task, A-E, is about a topic that might be included in the Computer Science curriculum that was created by the authors of this dataset.\n",
    "- For example, Task A asks the question: \"What is inheritance in object oriented programming?\"\n",
    "\n",
    "Four categories of plagiarism\n",
    "Each text file has an associated plagiarism label/category:\n",
    "\n",
    "- `cut`: An answer is plagiarized; it is copy-pasted directly from the relevant Wikipedia source text.\n",
    "- `light`: An answer is plagiarized; it is based on the Wikipedia source text and includes some copying and paraphrasing.\n",
    "- `heavy`: An answer is plagiarized; it is based on the Wikipedia source text but expressed using different words and structure. Since this doesn't copy directly from a source text, this will likely be the most challenging kind of plagiarism to detect.\n",
    "- `non`: An answer is not plagiarized; the Wikipedia source text is not used to create this answer.\n",
    "- `orig`: This is a specific category for the original, Wikipedia source text. Files for comparison purposes  only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of files:  100\nNumber of unique tasks/question types (A-E):  5\nUnique plagiarism categories:  ['non' 'cut' 'light' 'heavy' 'orig']\n"
     ]
    }
   ],
   "source": [
    "# print out some stats about the data\n",
    "print('Number of files: ', plagiarism_df.shape[0])  # .shape[0] gives the rows \n",
    "# .unique() gives unique items in a specified column\n",
    "print('Number of unique tasks/question types (A-E): ', (len(plagiarism_df['Task'].unique())))\n",
    "print('Unique plagiarism categories: ', (plagiarism_df['Category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTask:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  Task  Counts\n0    a      20\n1    b      20\n2    c      20\n3    d      20\n4    e      20",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPlagiarism Levels:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  Category  Counts\n0      cut      19\n1    heavy      19\n2    light      19\n3      non      38\n4     orig       5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cut</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>heavy</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>light</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>non</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>orig</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTask & Plagiarism Level Combos :\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   Task Category  Counts\n0     a      cut       4\n1     a    heavy       3\n2     a    light       3\n3     a      non       9\n4     a     orig       1\n5     b      cut       3\n6     b    heavy       4\n7     b    light       3\n8     b      non       9\n9     b     orig       1\n10    c      cut       3\n11    c    heavy       5\n12    c    light       4\n13    c      non       7\n14    c     orig       1\n15    d      cut       4\n16    d    heavy       4\n17    d    light       5\n18    d      non       6\n19    d     orig       1\n20    e      cut       5\n21    e    heavy       3\n22    e    light       4\n23    e      non       7\n24    e     orig       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Task</th>\n      <th>Category</th>\n      <th>Counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>cut</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>heavy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>light</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a</td>\n      <td>non</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>orig</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b</td>\n      <td>cut</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b</td>\n      <td>heavy</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>b</td>\n      <td>light</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b</td>\n      <td>non</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b</td>\n      <td>orig</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>c</td>\n      <td>cut</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>c</td>\n      <td>heavy</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>c</td>\n      <td>light</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>c</td>\n      <td>non</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>c</td>\n      <td>orig</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>d</td>\n      <td>cut</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>d</td>\n      <td>heavy</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>d</td>\n      <td>light</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>d</td>\n      <td>non</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>d</td>\n      <td>orig</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>e</td>\n      <td>cut</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>e</td>\n      <td>heavy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>e</td>\n      <td>light</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>e</td>\n      <td>non</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>e</td>\n      <td>orig</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Show counts by different tasks and amounts of plagiarism\n",
    "\n",
    "# group and count by task\n",
    "counts_per_task = plagiarism_df.groupby(['Task']).size().reset_index(name=\"Counts\")\n",
    "print(\"\\nTask:\")\n",
    "display(counts_per_task)\n",
    "\n",
    "# group by plagiarism level\n",
    "counts_per_category = plagiarism_df.groupby(['Category']).size().reset_index(name=\"Counts\")\n",
    "print(\"\\nPlagiarism Levels:\")\n",
    "display(counts_per_category)\n",
    "\n",
    "# group by task AND plagiarism level\n",
    "counts_task_and_plagiarism = plagiarism_df.groupby(['Task', 'Category']).size().reset_index(name=\"Counts\")\n",
    "print(\"\\nTask & Plagiarism Level Combos :\")\n",
    "display(counts_task_and_plagiarism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BarContainer object of 25 artists>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"302.878125pt\" version=\"1.1\" viewBox=\"0 0 474.1625 302.878125\" width=\"474.1625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-23T13:58:48.517191</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 302.878125 \nL 474.1625 302.878125 \nL 474.1625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 279 \nL 466.9625 279 \nL 466.9625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 40.853409 279 \nL 53.944318 279 \nL 53.944318 163.952381 \nL 40.853409 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 57.217045 279 \nL 70.307955 279 \nL 70.307955 192.714286 \nL 57.217045 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 73.580682 279 \nL 86.671591 279 \nL 86.671591 192.714286 \nL 73.580682 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 89.944318 279 \nL 103.035227 279 \nL 103.035227 20.142857 \nL 89.944318 20.142857 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 106.307955 279 \nL 119.398864 279 \nL 119.398864 250.238095 \nL 106.307955 250.238095 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 122.671591 279 \nL 135.7625 279 \nL 135.7625 192.714286 \nL 122.671591 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 139.035227 279 \nL 152.126136 279 \nL 152.126136 163.952381 \nL 139.035227 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 155.398864 279 \nL 168.489773 279 \nL 168.489773 192.714286 \nL 155.398864 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 171.7625 279 \nL 184.853409 279 \nL 184.853409 20.142857 \nL 171.7625 20.142857 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 188.126136 279 \nL 201.217045 279 \nL 201.217045 250.238095 \nL 188.126136 250.238095 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 204.489773 279 \nL 217.580682 279 \nL 217.580682 192.714286 \nL 204.489773 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 220.853409 279 \nL 233.944318 279 \nL 233.944318 135.190476 \nL 220.853409 135.190476 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 237.217045 279 \nL 250.307955 279 \nL 250.307955 163.952381 \nL 237.217045 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 253.580682 279 \nL 266.671591 279 \nL 266.671591 77.666667 \nL 253.580682 77.666667 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 269.944318 279 \nL 283.035227 279 \nL 283.035227 250.238095 \nL 269.944318 250.238095 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 286.307955 279 \nL 299.398864 279 \nL 299.398864 163.952381 \nL 286.307955 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 302.671591 279 \nL 315.7625 279 \nL 315.7625 163.952381 \nL 302.671591 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 319.035227 279 \nL 332.126136 279 \nL 332.126136 135.190476 \nL 319.035227 135.190476 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 335.398864 279 \nL 348.489773 279 \nL 348.489773 106.428571 \nL 335.398864 106.428571 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 351.7625 279 \nL 364.853409 279 \nL 364.853409 250.238095 \nL 351.7625 250.238095 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 368.126136 279 \nL 381.217045 279 \nL 381.217045 135.190476 \nL 368.126136 135.190476 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 384.489773 279 \nL 397.580682 279 \nL 397.580682 192.714286 \nL 384.489773 192.714286 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 400.853409 279 \nL 413.944318 279 \nL 413.944318 163.952381 \nL 400.853409 163.952381 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 417.217045 279 \nL 430.307955 279 \nL 430.307955 77.666667 \nL 417.217045 77.666667 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#pe93216adcc)\" d=\"M 433.580682 279 \nL 446.671591 279 \nL 446.671591 250.238095 \nL 433.580682 250.238095 \nz\n\" style=\"fill:#0000ff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mb97ca81d83\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.398864\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(44.217614 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.217045\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(126.035795 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.035227\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(204.672727 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"292.853409\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(286.490909 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"374.671591\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(368.309091 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"456.489773\" xlink:href=\"#mb97ca81d83\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(450.127273 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m341e0cdcd4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m341e0cdcd4\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 282.799219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m341e0cdcd4\" y=\"221.47619\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 225.275409)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m341e0cdcd4\" y=\"163.952381\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 167.7516)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m341e0cdcd4\" y=\"106.428571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 110.22779)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m341e0cdcd4\" y=\"48.904762\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 52.703981)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 20.5625 279 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 466.9625 279 \nL 466.9625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 20.5625 279 \nL 466.9625 279 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 20.5625 7.2 \nL 466.9625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe93216adcc\">\n   <rect height=\"271.8\" width=\"446.4\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# counts\n",
    "group = ['Task', 'Category']\n",
    "counts = plagiarism_df.groupby(group).size().reset_index(name=\"Counts\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(range(len(counts)), counts['Counts'], color = 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Tasks: \n",
    "- Clean and pre-process the data.\n",
    "- Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "- Select \"good\" features, by analyzing the correlations between different features.\n",
    "- Create train/test .csv files that hold the relevant features and class labels for train/test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import extra library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical to numerical data\n",
    "\n",
    "Two columns will be created to provide a numerical value for each of the samples. \n",
    "They are:\n",
    "- `Category`: labels to numerical labels according to the following rules (a higher value indicates a higher degree of plagiarism):\n",
    "    * 0 = non;\n",
    "    * 1 = heavy;\n",
    "    * 2 = light;\n",
    "    * 3 = cut;\n",
    "    * -1 = orig, this is a special value that indicates an original file.\n",
    "- `Class`: Any answer text that is not plagiarized (non) should have the class label 0. Any plagiarized answer texts should have the class label 1.\n",
    "And any orig texts will have a special label -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''Reads in a csv file which is assumed to have `File`, `Category` and `Task` columns.\n",
    "       This function does two things: \n",
    "       1) converts `Category` column values to numerical values \n",
    "       2) Adds a new, numerical `Class` label column.\n",
    "       The `Class` column will label plagiarized answers as 1 and non-plagiarized as 0.\n",
    "       Source texts have a special label, -1.\n",
    "       :param csv_file: The directory for the file_information.csv file\n",
    "       :return: A dataframe with numerical categories and a new `Class` label column'''\n",
    "    \n",
    "    # your code here\n",
    "    df = pd.read_csv(csv_file)\n",
    "    category_conversion = {\n",
    "        'non': 0,\n",
    "        'heavy': 1,\n",
    "        'light': 2,\n",
    "        'cut': 3, \n",
    "        'orig': -1\n",
    "    }\n",
    "\n",
    "    df[\"Category\"] = df[\"Category\"].apply(lambda x: category_conversion[x])\n",
    "    df[\"Class\"] = df[\"Category\"].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Task</th>\n      <th>Category</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>g0pA_taska.txt</td>\n      <td>a</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>g0pA_taskb.txt</td>\n      <td>b</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g0pA_taskc.txt</td>\n      <td>c</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g0pA_taskd.txt</td>\n      <td>d</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g0pA_taske.txt</td>\n      <td>e</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "# create new `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "# check that all categories of plagiarism have a class label = 1\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing and data spliting\n",
    "\n",
    "Two new columns will be created:\n",
    "* A Text column; this holds all the lowercase text for a File, with extraneous punctuation removed.\n",
    "* A Datatype column; this is a string value train, test, or orig that labels a data point as part of our train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# helper function for pre-processing text given a file\n",
    "def process_file(file):\n",
    "    # put text in all lower case letters \n",
    "    all_text = file.read().lower()\n",
    "\n",
    "    # remove all non-alphanumeric chars\n",
    "    all_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", all_text)\n",
    "    # remove newlines/tabs, etc. so it's easier to match phrases, later\n",
    "    all_text = re.sub(r\"\\t\", \" \", all_text)\n",
    "    all_text = re.sub(r\"\\n\", \" \", all_text)\n",
    "    all_text = re.sub(\"  \", \" \", all_text)\n",
    "    all_text = re.sub(\"   \", \" \", all_text)\n",
    "    \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text  \n",
       "0  inheritance is a basic concept of object orien...  \n",
       "1  pagerank is a link analysis algorithm used by ...  \n",
       "2  the vector space model also called term vector...  \n",
       "3  bayes theorem was names after rev thomas bayes...  \n",
       "4  dynamic programming is an algorithm design tec...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Task</th>\n      <th>Category</th>\n      <th>Class</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>g0pA_taska.txt</td>\n      <td>a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>inheritance is a basic concept of object orien...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>g0pA_taskb.txt</td>\n      <td>b</td>\n      <td>3</td>\n      <td>1</td>\n      <td>pagerank is a link analysis algorithm used by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g0pA_taskc.txt</td>\n      <td>c</td>\n      <td>2</td>\n      <td>1</td>\n      <td>the vector space model also called term vector...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g0pA_taskd.txt</td>\n      <td>d</td>\n      <td>1</td>\n      <td>1</td>\n      <td>bayes theorem was names after rev thomas bayes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g0pA_taske.txt</td>\n      <td>e</td>\n      <td>0</td>\n      <td>0</td>\n      <td>dynamic programming is an algorithm design tec...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# create a text column \n",
    "def create_text_column(df, file_directory='data/'):\n",
    "    '''Reads in the files, listed in a df and returns that df with an additional column, `Text`. \n",
    "       :param df: A dataframe of file information including a column for `File`\n",
    "       :param file_directory: the main directory where files are stored\n",
    "       :return: A dataframe with processed text '''\n",
    "   \n",
    "    # create copy to modify\n",
    "    text_df = df.copy()\n",
    "    \n",
    "    # store processed text\n",
    "    text = []\n",
    "    \n",
    "    # for each file (row) in the df, read in the file \n",
    "    for row_i in df.index:\n",
    "        filename = df.iloc[row_i]['File']\n",
    "        #print(filename)\n",
    "        file_path = file_directory + filename\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "\n",
    "            # standardize text using helper function\n",
    "            file_text = process_file(file)\n",
    "            # append processed text to list\n",
    "            text.append(file_text)\n",
    "    \n",
    "    # add column to the copied dataframe\n",
    "    text_df['Text'] = text\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "\n",
    "text_df = create_text_column(transformed_df)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function to label datatype for training 1 or test 2 \n",
    "def create_datatype(df, train_value, test_value, datatype_var, compare_dfcolumn, operator_of_compare, value_of_compare,\n",
    "                    sampling_number, sampling_seed):\n",
    "    # Subsets dataframe by condition relating to statement built from:\n",
    "    # 'compare_dfcolumn' 'operator_of_compare' 'value_of_compare'\n",
    "    df_subset = df[operator_of_compare(df[compare_dfcolumn], value_of_compare)]\n",
    "    df_subset = df_subset.drop(columns = [datatype_var])\n",
    "    \n",
    "    # Prints counts by task and compare_dfcolumn for subset df\n",
    "    #print(\"\\nCounts by Task & \" + compare_dfcolumn + \":\\n\", df_subset.groupby(['Task', compare_dfcolumn]).size().reset_index(name=\"Counts\") )\n",
    "    \n",
    "    # Sets all datatype to value for training for df_subset\n",
    "    df_subset.loc[:, datatype_var] = train_value\n",
    "    \n",
    "    # Performs stratified random sample of subset dataframe to create new df with subset values \n",
    "    df_sampled = df_subset.groupby(['Task', compare_dfcolumn], group_keys=False).apply(lambda x: x.sample(min(len(x), sampling_number), random_state = sampling_seed))\n",
    "    df_sampled = df_sampled.drop(columns = [datatype_var])\n",
    "    # Sets all datatype to value for test_value for df_sampled\n",
    "    df_sampled.loc[:, datatype_var] = test_value\n",
    "    \n",
    "    # Prints counts by compare_dfcolumn for selected sample\n",
    "    #print(\"\\nCounts by \"+ compare_dfcolumn + \":\\n\", df_sampled.groupby([compare_dfcolumn]).size().reset_index(name=\"Counts\") )\n",
    "    #print(\"\\nSampled DF:\\n\",df_sampled)\n",
    "    \n",
    "    # Labels all datatype_var column as train_value which will be overwritten to \n",
    "    # test_value in next for loop for all test cases chosen with stratified sample\n",
    "    for index in df_sampled.index: \n",
    "        # Labels all datatype_var columns with test_value for straified test sample\n",
    "        df_subset.loc[index, datatype_var] = test_value\n",
    "\n",
    "    #print(\"\\nSubset DF:\\n\",df_subset)\n",
    "    # Adds test_value and train_value for all relevant data in main dataframe\n",
    "    for index in df_subset.index:\n",
    "        # Labels all datatype_var columns in df with train_value/test_value based upon \n",
    "        # stratified test sample and subset of df\n",
    "        df.loc[index, datatype_var] = df_subset.loc[index, datatype_var]\n",
    "\n",
    "    # returns nothing because dataframe df already altered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              File Task  Category  Class  \\\n",
       "0   g0pA_taska.txt    a         0      0   \n",
       "1   g0pA_taskb.txt    b         3      1   \n",
       "2   g0pA_taskc.txt    c         2      1   \n",
       "3   g0pA_taskd.txt    d         1      1   \n",
       "4   g0pA_taske.txt    e         0      0   \n",
       "5   g0pB_taska.txt    a         0      0   \n",
       "6   g0pB_taskb.txt    b         0      0   \n",
       "7   g0pB_taskc.txt    c         3      1   \n",
       "8   g0pB_taskd.txt    d         2      1   \n",
       "9   g0pB_taske.txt    e         1      1   \n",
       "10  g0pC_taska.txt    a         1      1   \n",
       "11  g0pC_taskb.txt    b         0      0   \n",
       "12  g0pC_taskc.txt    c         0      0   \n",
       "13  g0pC_taskd.txt    d         3      1   \n",
       "14  g0pC_taske.txt    e         2      1   \n",
       "15  g0pD_taska.txt    a         3      1   \n",
       "16  g0pD_taskb.txt    b         2      1   \n",
       "17  g0pD_taskc.txt    c         1      1   \n",
       "18  g0pD_taskd.txt    d         0      0   \n",
       "19  g0pD_taske.txt    e         0      0   \n",
       "\n",
       "                                                 Text Datatype  \n",
       "0   inheritance is a basic concept of object orien...    train  \n",
       "1   pagerank is a link analysis algorithm used by ...     test  \n",
       "2   the vector space model also called term vector...    train  \n",
       "3   bayes theorem was names after rev thomas bayes...    train  \n",
       "4   dynamic programming is an algorithm design tec...    train  \n",
       "5   inheritance is a basic concept in object orien...    train  \n",
       "6   pagerank pr refers to both the concept and the...    train  \n",
       "7   vector space model is an algebraic model for r...     test  \n",
       "8   bayes theorem relates the conditional and marg...    train  \n",
       "9   dynamic programming is a method for solving ma...     test  \n",
       "10  inheritance in object oriented programming is ...     test  \n",
       "11  there are many attributes which infulance the ...    train  \n",
       "12  the vector space model is where each document ...    train  \n",
       "13  in probability theory bayes theorem often call...    train  \n",
       "14  in computer science dynamic programming is a w...    train  \n",
       "15  inheritance in object oriented programming is ...    train  \n",
       "16  pagerank algorithm is patented by stanford uni...     test  \n",
       "17  an algebraic model for representing text docum...    train  \n",
       "18  baye s theorm in connection with conditional p...    train  \n",
       "19  dynamic programming dp is an extremely powerfu...    train  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Task</th>\n      <th>Category</th>\n      <th>Class</th>\n      <th>Text</th>\n      <th>Datatype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>g0pA_taska.txt</td>\n      <td>a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>inheritance is a basic concept of object orien...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>g0pA_taskb.txt</td>\n      <td>b</td>\n      <td>3</td>\n      <td>1</td>\n      <td>pagerank is a link analysis algorithm used by ...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g0pA_taskc.txt</td>\n      <td>c</td>\n      <td>2</td>\n      <td>1</td>\n      <td>the vector space model also called term vector...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g0pA_taskd.txt</td>\n      <td>d</td>\n      <td>1</td>\n      <td>1</td>\n      <td>bayes theorem was names after rev thomas bayes...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g0pA_taske.txt</td>\n      <td>e</td>\n      <td>0</td>\n      <td>0</td>\n      <td>dynamic programming is an algorithm design tec...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>g0pB_taska.txt</td>\n      <td>a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>inheritance is a basic concept in object orien...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>g0pB_taskb.txt</td>\n      <td>b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>pagerank pr refers to both the concept and the...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>g0pB_taskc.txt</td>\n      <td>c</td>\n      <td>3</td>\n      <td>1</td>\n      <td>vector space model is an algebraic model for r...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>g0pB_taskd.txt</td>\n      <td>d</td>\n      <td>2</td>\n      <td>1</td>\n      <td>bayes theorem relates the conditional and marg...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>g0pB_taske.txt</td>\n      <td>e</td>\n      <td>1</td>\n      <td>1</td>\n      <td>dynamic programming is a method for solving ma...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>g0pC_taska.txt</td>\n      <td>a</td>\n      <td>1</td>\n      <td>1</td>\n      <td>inheritance in object oriented programming is ...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>g0pC_taskb.txt</td>\n      <td>b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>there are many attributes which infulance the ...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>g0pC_taskc.txt</td>\n      <td>c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>the vector space model is where each document ...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>g0pC_taskd.txt</td>\n      <td>d</td>\n      <td>3</td>\n      <td>1</td>\n      <td>in probability theory bayes theorem often call...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>g0pC_taske.txt</td>\n      <td>e</td>\n      <td>2</td>\n      <td>1</td>\n      <td>in computer science dynamic programming is a w...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>g0pD_taska.txt</td>\n      <td>a</td>\n      <td>3</td>\n      <td>1</td>\n      <td>inheritance in object oriented programming is ...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>g0pD_taskb.txt</td>\n      <td>b</td>\n      <td>2</td>\n      <td>1</td>\n      <td>pagerank algorithm is patented by stanford uni...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>g0pD_taskc.txt</td>\n      <td>c</td>\n      <td>1</td>\n      <td>1</td>\n      <td>an algebraic model for representing text docum...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>g0pD_taskd.txt</td>\n      <td>d</td>\n      <td>0</td>\n      <td>0</td>\n      <td>baye s theorm in connection with conditional p...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>g0pD_taske.txt</td>\n      <td>e</td>\n      <td>0</td>\n      <td>0</td>\n      <td>dynamic programming dp is an extremely powerfu...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import operator \n",
    "# create new df with Datatype (train, test, orig) column\n",
    "def train_test_dataframe(clean_df, random_seed=100):\n",
    "    new_df = clean_df.copy()\n",
    "    # Initialize datatype as 0 initially for all records - after function 0 will remain only for original wiki answers\n",
    "    new_df.loc[:,'Datatype'] = 0\n",
    "    # Creates test & training datatypes for plagiarized answers (1,2,3)\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.gt, 0, 1, random_seed)\n",
    "    # Creates test & training datatypes for NON-plagiarized answers (0)\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.eq, 0, 2, random_seed)\n",
    "    # creating a dictionary of categorical:numerical mappings for plagiarsm categories\n",
    "    mapping = {0:'orig', 1:'train', 2:'test'} \n",
    "    # traversing through dataframe and replacing categorical data\n",
    "    new_df.Datatype = [mapping[item] for item in new_df.Datatype] \n",
    "    return new_df\n",
    "\n",
    "\n",
    "random_seed = 1 # can change; set for reproducibility\n",
    "\n",
    "# pass in `text_df` from above to create a complete dataframe, with all the information you need\n",
    "complete_df = train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "# check results\n",
    "complete_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity features\n",
    "One of the ways we might go about detecting plagiarism, is by computing similarity features that measure how similar a given answer text is as compared to the original wikipedia source text (for a specific task, a-e). The similarity features are informed by [this paper on plagiarism detection](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf).\n",
    "In this paper, researchers created features called __containment__ and __longest common subsequence__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Containment calculation\n",
    "\n",
    "The general steps to complete this function are as follows:\n",
    "\n",
    "1. From all of the text files in a given df, create an array of n-gram counts; it is suggested that you use a CountVectorizer for this purpose.\n",
    "2. Get the processed answer and source texts for the given answer_filename.\n",
    "3. Calculate the containment between an answer and source text according to the following equation.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "4. Return that containment value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "\n",
    "    source_filename = 'orig_' + answer_filename.split('_')[1]\n",
    "    answer_text = df[df['File'] == answer_filename].iloc[0]['Text']\n",
    "    source_text = df[df['File'] == source_filename].iloc[0]['Text']\n",
    "  \n",
    "    cv = CountVectorizer(ngram_range=(n,n))\n",
    "    matrix = cv.fit_transform([answer_text, source_text]).toarray()\n",
    "    \n",
    "    intersection = np.min(matrix, 0)\n",
    "    \n",
    "    return sum(intersection)/sum(matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original category values: \n [0, 3, 2, 1, 0]\n\n3-gram containment values: \n [0.009345794392523364, 0.9641025641025641, 0.6136363636363636, 0.15675675675675677, 0.031746031746031744]\n"
     ]
    }
   ],
   "source": [
    "# select a value for n\n",
    "n = 3\n",
    "\n",
    "# indices for first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "# iterate through files and calculate containment\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "    # get level of plagiarism for a given file index\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # calculate containment for given file and n\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longest Common Subsequence\n",
    "\n",
    "It may be helpful to think of this in a concrete example. A Longest Common Subsequence (LCS) problem may look as follows:\n",
    "\n",
    "* Given two texts: text A (answer text) of length n, and string S (original source text) of length m. Our goal is to produce their longest common subsequence of words: the longest sequence of words that appear left-to-right in both texts (though the words don't have to be in continuous order).\n",
    "* Consider:\n",
    "\n",
    "    * A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "    * S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "- In this case, we can see that the start of each sentence of fairly similar, having overlap in the sequence of words, \"pagerank is a link analysis algorithm used by\" before diverging slightly. Then we continue moving left -to-right along both texts until we see the next common sequence; in this case it is only one word, \"google\". Next we find \"that\" and \"a\" and finally the same ending \"to each element of a hyperlinked set of documents\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an answer text and a source text\n",
    "def lcs_norm_word(answer_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param answer_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    \n",
    "    answer_words = [''] + answer_text.split()\n",
    "    source_words = [''] + source_text.split()\n",
    "    \n",
    "    # Prepare matrix for Dynamic Programmaing\n",
    "    matrix = np.zeros((len(answer_words), len(source_words)))\n",
    "    \n",
    "    for i in range(1, len(answer_words)):\n",
    "        for j in range(1, len(source_words)):\n",
    "            matrix[i][j] = (matrix[i-1][j-1] + 1) if (source_words[j] == answer_words[i]) else max(matrix[i-1][j], matrix[i][j-1])\n",
    "          \n",
    "    return matrix[-1,-1] / (len(answer_words) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LCS =  0.7407407407407407\nTest passed!\n"
     ]
    }
   ],
   "source": [
    "# Run the test scenario from above\n",
    "# does your function return the expected value?\n",
    "\n",
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "# calculate LCS\n",
    "lcs = lcs_norm_word(A, S)\n",
    "print('LCS = ', lcs)\n",
    "\n",
    "\n",
    "# expected value test\n",
    "assert lcs==20/27., \"Incorrect LCS value, expected about 0.7408, got \"+str(lcs)\n",
    "\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original category values: \n [0, 3, 2, 1, 0]\n\nNormalized LCS values: \n [0.1917808219178082, 0.8207547169811321, 0.8464912280701754, 0.3160621761658031, 0.24257425742574257]\n"
     ]
    }
   ],
   "source": [
    "# test on your own\n",
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] \n",
    "    task = complete_df.loc[i, 'Task']\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)]\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "    source_text = orig_row['Text'].values[0]\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all features\n",
    "### Multiple containment features\n",
    "This function returns a list of containment features, calculated for a given n and for all files in a df (assumed to the the complete_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns a list of containment features, calculated for a given n \n",
    "# Should return a list of length 100 for all files in a complete_df\n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    # iterates through dataframe rows\n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function creates lcs feature and add it to the dataframe\n",
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    # iterate through files in dataframe\n",
    "    for i in df.index:\n",
    "        # Computes LCS_norm words feature using function above for answer tasks\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            # get texts to compare\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            # we know that source texts have Class = -1\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        # Sets to -1 for original tasks \n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell I define an n-gram range; these will be the n's I use to create n-gram containment features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "7-gram containment features created!\n",
      "8-gram containment features created!\n",
      "9-gram containment features created!\n",
      "10-gram containment features created!\n",
      "11-gram containment features created!\n",
      "12-gram containment features created!\n",
      "13-gram containment features created!\n",
      "14-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'c_8', 'c_9', 'c_10', 'c_11', 'c_12', 'c_13', 'c_14', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,15)\n",
    "\n",
    "features_list = []\n",
    "\n",
    "# Create features in a features_df\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0   0.398148  0.079070  0.009346  0.000000  0.000000  0.000000  0.000000   \n",
       "1   1.000000  0.984694  0.964103  0.943299  0.922280  0.901042  0.879581   \n",
       "2   0.869369  0.719457  0.613636  0.515982  0.449541  0.382488  0.319444   \n",
       "3   0.593583  0.268817  0.156757  0.108696  0.081967  0.060440  0.044199   \n",
       "4   0.544503  0.115789  0.031746  0.005319  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "96 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "97 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "98 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "99 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "\n",
       "         c_8       c_9      c_10      c_11      c_12      c_13      c_14  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.857895  0.835979  0.813830  0.791444  0.768817  0.745946  0.722826   \n",
       "2   0.265116  0.219626  0.197183  0.174528  0.151659  0.133333  0.114833   \n",
       "3   0.027778  0.011173  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "96 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "97 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "98 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "99 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "\n",
       "    lcs_word  \n",
       "0   0.191781  \n",
       "1   0.820755  \n",
       "2   0.846491  \n",
       "3   0.316062  \n",
       "4   0.242574  \n",
       "..       ...  \n",
       "95 -1.000000  \n",
       "96 -1.000000  \n",
       "97 -1.000000  \n",
       "98 -1.000000  \n",
       "99 -1.000000  \n",
       "\n",
       "[100 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_1</th>\n      <th>c_2</th>\n      <th>c_3</th>\n      <th>c_4</th>\n      <th>c_5</th>\n      <th>c_6</th>\n      <th>c_7</th>\n      <th>c_8</th>\n      <th>c_9</th>\n      <th>c_10</th>\n      <th>c_11</th>\n      <th>c_12</th>\n      <th>c_13</th>\n      <th>c_14</th>\n      <th>lcs_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.398148</td>\n      <td>0.079070</td>\n      <td>0.009346</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.191781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.984694</td>\n      <td>0.964103</td>\n      <td>0.943299</td>\n      <td>0.922280</td>\n      <td>0.901042</td>\n      <td>0.879581</td>\n      <td>0.857895</td>\n      <td>0.835979</td>\n      <td>0.813830</td>\n      <td>0.791444</td>\n      <td>0.768817</td>\n      <td>0.745946</td>\n      <td>0.722826</td>\n      <td>0.820755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.869369</td>\n      <td>0.719457</td>\n      <td>0.613636</td>\n      <td>0.515982</td>\n      <td>0.449541</td>\n      <td>0.382488</td>\n      <td>0.319444</td>\n      <td>0.265116</td>\n      <td>0.219626</td>\n      <td>0.197183</td>\n      <td>0.174528</td>\n      <td>0.151659</td>\n      <td>0.133333</td>\n      <td>0.114833</td>\n      <td>0.846491</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.593583</td>\n      <td>0.268817</td>\n      <td>0.156757</td>\n      <td>0.108696</td>\n      <td>0.081967</td>\n      <td>0.060440</td>\n      <td>0.044199</td>\n      <td>0.027778</td>\n      <td>0.011173</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.316062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.544503</td>\n      <td>0.115789</td>\n      <td>0.031746</td>\n      <td>0.005319</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.242574</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# print some results \n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated features\n",
    "Some features are too highly-correlated. We have to extract only some features that present a lower correlation to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "           c_1   c_2   c_3   c_4   c_5   c_6   c_7   c_8   c_9  c_10  c_11  \\\nc_1       1.00  0.94  0.90  0.89  0.88  0.87  0.87  0.87  0.86  0.86  0.86   \nc_2       0.94  1.00  0.99  0.98  0.97  0.96  0.95  0.94  0.94  0.93  0.92   \nc_3       0.90  0.99  1.00  1.00  0.99  0.98  0.98  0.97  0.96  0.95  0.95   \nc_4       0.89  0.98  1.00  1.00  1.00  0.99  0.99  0.98  0.98  0.97  0.97   \nc_5       0.88  0.97  0.99  1.00  1.00  1.00  1.00  0.99  0.99  0.98  0.98   \nc_6       0.87  0.96  0.98  0.99  1.00  1.00  1.00  1.00  0.99  0.99  0.99   \nc_7       0.87  0.95  0.98  0.99  1.00  1.00  1.00  1.00  1.00  1.00  0.99   \nc_8       0.87  0.94  0.97  0.98  0.99  1.00  1.00  1.00  1.00  1.00  1.00   \nc_9       0.86  0.94  0.96  0.98  0.99  0.99  1.00  1.00  1.00  1.00  1.00   \nc_10      0.86  0.93  0.95  0.97  0.98  0.99  1.00  1.00  1.00  1.00  1.00   \nc_11      0.86  0.92  0.95  0.97  0.98  0.99  0.99  1.00  1.00  1.00  1.00   \nc_12      0.86  0.92  0.94  0.96  0.97  0.98  0.99  0.99  1.00  1.00  1.00   \nc_13      0.86  0.91  0.94  0.96  0.97  0.98  0.99  0.99  1.00  1.00  1.00   \nc_14      0.86  0.91  0.93  0.95  0.97  0.98  0.98  0.99  0.99  1.00  1.00   \nlcs_word  0.97  0.98  0.97  0.95  0.95  0.94  0.93  0.92  0.91  0.91  0.90   \n\n          c_12  c_13  c_14  lcs_word  \nc_1       0.86  0.86  0.86      0.97  \nc_2       0.92  0.91  0.91      0.98  \nc_3       0.94  0.94  0.93      0.97  \nc_4       0.96  0.96  0.95      0.95  \nc_5       0.97  0.97  0.97      0.95  \nc_6       0.98  0.98  0.98      0.94  \nc_7       0.99  0.99  0.98      0.93  \nc_8       0.99  0.99  0.99      0.92  \nc_9       1.00  1.00  0.99      0.91  \nc_10      1.00  1.00  1.00      0.91  \nc_11      1.00  1.00  1.00      0.90  \nc_12      1.00  1.00  1.00      0.90  \nc_13      1.00  1.00  1.00      0.90  \nc_14      1.00  1.00  1.00      0.90  \nlcs_word  0.90  0.90  0.90      1.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_1</th>\n      <th>c_2</th>\n      <th>c_3</th>\n      <th>c_4</th>\n      <th>c_5</th>\n      <th>c_6</th>\n      <th>c_7</th>\n      <th>c_8</th>\n      <th>c_9</th>\n      <th>c_10</th>\n      <th>c_11</th>\n      <th>c_12</th>\n      <th>c_13</th>\n      <th>c_14</th>\n      <th>lcs_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c_1</th>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.90</td>\n      <td>0.89</td>\n      <td>0.88</td>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>c_2</th>\n      <td>0.94</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.97</td>\n      <td>0.96</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.93</td>\n      <td>0.92</td>\n      <td>0.92</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.98</td>\n    </tr>\n    <tr>\n      <th>c_3</th>\n      <td>0.90</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.97</td>\n      <td>0.96</td>\n      <td>0.95</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.93</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>c_4</th>\n      <td>0.89</td>\n      <td>0.98</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.97</td>\n      <td>0.97</td>\n      <td>0.96</td>\n      <td>0.96</td>\n      <td>0.95</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>c_5</th>\n      <td>0.88</td>\n      <td>0.97</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.97</td>\n      <td>0.97</td>\n      <td>0.97</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>c_6</th>\n      <td>0.87</td>\n      <td>0.96</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>c_7</th>\n      <td>0.87</td>\n      <td>0.95</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>c_8</th>\n      <td>0.87</td>\n      <td>0.94</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>c_9</th>\n      <td>0.86</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.91</td>\n    </tr>\n    <tr>\n      <th>c_10</th>\n      <td>0.86</td>\n      <td>0.93</td>\n      <td>0.95</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.91</td>\n    </tr>\n    <tr>\n      <th>c_11</th>\n      <td>0.86</td>\n      <td>0.92</td>\n      <td>0.95</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>c_12</th>\n      <td>0.86</td>\n      <td>0.92</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>c_13</th>\n      <td>0.86</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>c_14</th>\n      <td>0.86</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.95</td>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>lcs_word</th>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.97</td>\n      <td>0.95</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>0.93</td>\n      <td>0.92</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.90</td>\n      <td>0.90</td>\n      <td>0.90</td>\n      <td>0.90</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Create correlation matrix for just Features to determine different models to test\n",
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "\n",
    "# display shows all of a dataframe\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes in dataframes and a list of selected features (column names) and returns (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''Gets selected training and test features from given dataframes, and \n",
    "       returns tuples for training and test features and their corresponding class labels.\n",
    "       :param complete_df: A dataframe with all of our processed text data, datatypes, and labels\n",
    "       :param features_df: A dataframe of all computed, similarity features\n",
    "       :param selected_features: An array of selected features that correspond to certain columns in `features_df`\n",
    "       :return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    \n",
    "    # get the training features\n",
    "    train_x = features_df[complete_df['Datatype'] == 'train'][selected_features].to_numpy()\n",
    "    # And training class labels (0 or 1)\n",
    "    train_y = complete_df[complete_df['Datatype'] == 'train']['Category'].to_numpy()\n",
    "    \n",
    "    # get the test features and labels\n",
    "    test_x = features_df[complete_df['Datatype'] == 'test'][selected_features].to_numpy()\n",
    "    test_y = complete_df[complete_df['Datatype'] == 'test']['Category'].to_numpy()\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features\n",
    "Select two of the features that are not that correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training size:  70\nTest size:  25\n\nTraining df sample: \n [[0.39814815 0.        ]\n [0.86936937 0.44954128]\n [0.59358289 0.08196721]\n [0.54450262 0.        ]\n [0.32950192 0.        ]\n [0.59030837 0.        ]\n [0.75977654 0.24571429]\n [0.51612903 0.        ]\n [0.44086022 0.        ]\n [0.97945205 0.78873239]]\n"
     ]
    }
   ],
   "source": [
    "# Select your list of features, this should be column names from features_df\n",
    "# ex. ['c_1', 'lcs_word']\n",
    "selected_features = ['c_1', 'c_5']\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# check that division of samples seems correct\n",
    "# these should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating final data files\n",
    "\n",
    "In this project, SageMaker will expect the following format for train/test data:\n",
    "\n",
    "- Training and test data should be saved in one .csv file each, ex train.csv and test.csv\n",
    "- These files should have class labels in the first column and features in the rest of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # your code here\n",
    "    pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1).dropna().to_csv(data_dir+'/'+filename, index=False, header=False)\n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Path created: test_csv/to_delete.csv\nTests passed!\n"
     ]
    }
   ],
   "source": [
    "fake_x = [ [0.39814815, 0.0001, 0.19178082], \n",
    "           [0.86936937, 0.44954128, 0.84649123], \n",
    "           [0.44086022, 0., 0.22395833] ]\n",
    "\n",
    "fake_y = [0, 1, 1]\n",
    "\n",
    "make_csv(fake_x, fake_y, filename='to_delete.csv', data_dir='test_csv')\n",
    "\n",
    "# read in and test dimensions\n",
    "fake_df = pd.read_csv('test_csv/to_delete.csv', header=None)\n",
    "\n",
    "# check shape\n",
    "assert fake_df.shape==(3, 4), \\\n",
    "      'The file should have as many rows as data_points and as many columns as features+1 (for indices).'\n",
    "# check that first column = labels\n",
    "assert np.all(fake_df.iloc[:,0].values==fake_y), 'First column is not equal to the labels, fake_y.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the test csv file, generated above\n",
    "! rm -rf test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Path created: plagiarism_data/train.csv\nPath created: plagiarism_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# create train.csv and test.csv files in a directory\n",
    "# to be specified when uploading data to S3\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session(session)\n",
    "\n",
    "try:\n",
    "    role = os.environ['AWS_INSTANCE_ROLE']\n",
    "except:\n",
    "    role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "try:\n",
    "    bucket = os.environ['AWS_PROJECT_BUCKET']\n",
    "except:\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# name of directory created to save features data\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'plagiarism_project'\n",
    "\n",
    "# folder in S3 to save data to\n",
    "output_path = f's3://{bucket}/{prefix}/output'\n",
    "code_path = f's3://{bucket}/{prefix}/code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload all data to S3\n",
    "s3_path = sagemaker_session.upload_data(key_prefix=prefix, bucket=bucket, path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "plagiarism_project/test.csv\nplagiarism_project/train.csv\nTest passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Here I'm going to use SKLearn from Sagemaker module in order to define an estimator. The `train.py` script is used as source for the training routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "# your import and estimator code, here\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                   source_dir='source_sklearn',\n",
    "                    output_path=output_path,\n",
    "                    code_path=code_path,\n",
    "                   role=role,\n",
    "                   instance_count=1,\n",
    "                   instance_type='ml.c4.xlarge',\n",
    "                    framework_version='0.23-1',\n",
    "                   sagemaker_session=sagemaker_session,\n",
    "                   hyperparameters= {\n",
    "                       'neighbors': 10\n",
    "                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': s3_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------!CPU times: user 360 ms, sys: 5.38 ms, total: 366 ms\n",
      "Wall time: 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = estimator.deploy(instance_type='ml.t2.medium', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# First: generate predicted, class labels\n",
    "test_y_preds = predictor.predict(test_x)\n",
    "\n",
    "# test that model generates the correct number of labels\n",
    "assert len(test_y_preds)==len(test_y), 'Unexpected number of predictions.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "\n",
      "Predicted class labels: \n",
      "[3 2 1 0 2 3 0 0 0 0 0 0 0 3 3 2 2 3 0 3 0 3 3 0 0]\n",
      "\n",
      "True class labels: \n",
      "[3 3 1 1 2 2 0 0 0 0 0 0 1 2 3 1 2 3 0 3 0 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Second: calculate the test accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_y, test_y_preds)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "## print out the array of predicted and true labels, if you want\n",
    "print('\\nPredicted class labels: ')\n",
    "print(test_y_preds)\n",
    "print('\\nTrue class labels: ')\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3\n",
       "0  10  0  0  0\n",
       "1   2  1  1  1\n",
       "2   0  0  2  3\n",
       "3   0  0  1  4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_matrix = pd.DataFrame(np.zeros((4,4), int))\n",
    "\n",
    "for real, pred in zip(test_y, test_y_preds):\n",
    "    prediction_matrix.iloc[real, pred] += 1\n",
    "    \n",
    "# Row: true label, \n",
    "# Column: predicted label\n",
    "prediction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '3CD940A17891733B',\n",
       "   'HostId': 'xxvp7LQ2V+NiSEoQJbwJAx9JqBe7IWTXWVHZZ+IKNkjMz9yIaUq4oiGY2Hhgn0Km0G3mAgcsyaM=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'xxvp7LQ2V+NiSEoQJbwJAx9JqBe7IWTXWVHZZ+IKNkjMz9yIaUq4oiGY2Hhgn0Km0G3mAgcsyaM=',\n",
       "    'x-amz-request-id': '3CD940A17891733B',\n",
       "    'date': 'Sat, 07 Nov 2020 20:13:25 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'plagiarism_project/test.csv'},\n",
       "   {'Key': 'plagiarism_project/train.csv'},\n",
       "   {'Key': 'plagiarism_project/output/sagemaker-scikit-learn-2020-11-07-19-39-58-828/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-11-07-19-39-58-828/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'plagiarism_project/output/sagemaker-scikit-learn-2020-11-07-19-39-58-828/output/model.tar.gz'}]}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}